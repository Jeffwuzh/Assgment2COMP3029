{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import datasets, models, transforms\n",
    "import time\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# 是否使用gpu运算\n",
    "use_gpu = torch.cuda.is_available()\n",
    "print(use_gpu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 定义数据的处理方式，数据增强\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        # 将图像进行缩放，缩放为256*256\n",
    "        transforms.Resize(256),\n",
    "        # 在256*256的图像上随机裁剪出227*227大小的图像用于训练\n",
    "        transforms.RandomResizedCrop(227),\n",
    "        # 图像用于翻转\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        # 转换成tensor向量\n",
    "        transforms.ToTensor(),\n",
    "        # 对图像进行归一化操作\n",
    "        # [0.485, 0.456, 0.406]，RGB通道的均值与标准差\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    # 验证集中心裁剪，甚至不裁剪，直接缩放为224*224\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(227),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 定义数据读入\n",
    "def Load_Image_Information(path):\n",
    "    # 图像存储路径\n",
    "    image_Root_Dir = r\"./\"\n",
    "    # 获取图像的路径\n",
    "    iamge_Dir = os.path.join(image_Root_Dir, path)\n",
    "    # 以RGB格式打开图像\n",
    "    # Pytorch DataLoader就是使用PIL所读取的图像格式\n",
    "    # 建议就用这种方法读取图像，当读入灰度图像时convert('')\n",
    "    return Image.open(iamge_Dir).convert('RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 定义自己数据集的数据读入类  torch特有的数据集读取方式\n",
    "class my_Data_Set(nn.Module):\n",
    "    def __init__(self, txt, transform=None, target_transform=None, loader=None):\n",
    "        super(my_Data_Set, self).__init__()\n",
    "        # 打开存储图像名与标签的txt文件\n",
    "        fp = open(txt, 'r')\n",
    "        images = []\n",
    "        labels = []\n",
    "        # 将图像名和图像标签对应存储起来\n",
    "        for line in fp:\n",
    "            line.strip('\\n')\n",
    "            line.rstrip()\n",
    "            information = line.split()\n",
    "            images.append(information[0])\n",
    "            # 将标签信息由str类型转换为float类型\n",
    "            labels.append([float(l) for l in information[1:len(information)]])\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.loader = loader\n",
    "\n",
    "    # 重写这个函数用来进行图像数据的读取\n",
    "    def __getitem__(self, item):\n",
    "        # 获取图像名和标签\n",
    "        imageName = self.images[item]\n",
    "        label = self.labels[item]\n",
    "        # 读入图像信息\n",
    "        image = self.loader(imageName)\n",
    "        # 处理图像数据\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        # 需要将标签转换为float类型，BCELoss只接受float类型\n",
    "        label = torch.FloatTensor(label)\n",
    "        return image, label\n",
    "    # 重写这个函数，来看数据集中含有多少数据\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成Pytorch所需的DataLoader数据输入格式\n",
    "train_Data = my_Data_Set(r'./train.txt', transform=data_transforms['train'], loader=Load_Image_Information)\n",
    "val_Data = my_Data_Set(r'./test.txt', transform=data_transforms['val'], loader=Load_Image_Information)\n",
    "train_DataLoader = DataLoader(train_Data, batch_size=10, shuffle=True)\n",
    "val_DataLoader = DataLoader(val_Data, batch_size=10)\n",
    "dataloaders = {'train':train_DataLoader, 'val':val_DataLoader}\n",
    "# 读取数据集大小\n",
    "dataset_sizes = {'train': train_Data.__len__(), 'val': val_Data.__len__()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#需要保存的\n",
    "file1 = open(\"./savetxt/save_trainloss.txt\",\"w\")\n",
    "file2 = open(\"./savetxt/save_valloss.txt\",\"w\")\n",
    "file3 = open(\"./savetxt/save_trainacc.txt\",\"w\")\n",
    "file4 = open(\"./savetxt/save_valacc.txt\",\"w\")\n",
    "file5 = open(\"./savetxt/save_f1score.txt\",\"w\")\n",
    "file6 = open(\"./savetxt/save_precision.txt\",\"w\")\n",
    "file7 = open(\"./savetxt/save_recall.txt\",\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#训练\n",
    "\n",
    "# 训练与验证网络（所有层都参加训练） \n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    Sigmoid_fun = nn.Sigmoid()\n",
    "    since = time.time()\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        # 每训练一个epoch，验证一下网络模型\n",
    "        for phase in ['train', 'val']:\n",
    "            running_loss = 0.0\n",
    "            running_precision = 0.0\n",
    "            running_recall = 0.0\n",
    "            batch_num = 0\n",
    "            if phase == 'train':\n",
    "                # 学习率更新方式\n",
    "                scheduler.step()\n",
    "                #  调用模型训练\n",
    "                model.train()\n",
    "                # 依次获取所有图像，参与模型训练或测试\n",
    "                for data in dataloaders[phase]:\n",
    "                    # 获取输入\n",
    "                    inputs, labels = data\n",
    "                    # 判断是否使用gpu\n",
    "                    if use_gpu:\n",
    "                        inputs = inputs.cuda()\n",
    "                        labels = labels.cuda()\n",
    "                    # 梯度清零\n",
    "                    optimizer.zero_grad()\n",
    "                    # 网络前向运行\n",
    "                    outputs = model(inputs)\n",
    "                    # 计算Loss值\n",
    "                    loss = criterion(Sigmoid_fun(outputs), labels)\n",
    "                    # 这里根据自己的需求选择模型预测结果准确率的函数\n",
    "                    precision, recall = calculate_acuracy_mode_one(Sigmoid_fun(outputs), labels)\n",
    "           \n",
    "                    running_precision += precision\n",
    "                    running_recall += recall\n",
    "                    batch_num += 1\n",
    "                    # 反传梯度\n",
    "                    loss.backward()\n",
    "                    # 更新权重\n",
    "                    optimizer.step()\n",
    "                    # 计算一个epoch的loss值和准确率\n",
    "                    running_loss += loss.item() * inputs.size(0)\n",
    "            else:\n",
    "                # 取消验证阶段的梯度\n",
    "                with torch.no_grad():\n",
    "                    # 调用模型测试\n",
    "                    model.eval()\n",
    "                    # 依次获取所有图像，参与模型训练或测试\n",
    "                    for data in dataloaders[phase]:\n",
    "                        # 获取输入\n",
    "                        inputs, labels = data\n",
    "                        # 判断是否使用gpu\n",
    "                        if use_gpu:\n",
    "                            inputs = inputs.cuda()\n",
    "                            labels = labels.cuda()\n",
    "                        # 网络前向运行\n",
    "                        outputs = model(inputs)\n",
    "                        # 计算Loss值\n",
    "                        # BCELoss的输入（1、网络模型的输出必须经过sigmoid；2、标签必须是float类型的tensor）\n",
    "                        loss = criterion(Sigmoid_fun(outputs), labels)\n",
    "                        # 计算一个epoch的loss值和准确率\n",
    "                        running_loss += loss.item() * inputs.size(0)\n",
    "                        # 这里根据自己的需求选择模型预测结果准确率的函数\n",
    "                        precision, recall = calculate_acuracy_mode_one(Sigmoid_fun(outputs), labels)\n",
    "                        running_precision += precision\n",
    "                        running_recall += recall\n",
    "                        batch_num += 1\n",
    "\n",
    "            # 计算Loss和准确率的均值\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            print('{} Loss: {:.4f} '.format(phase, epoch_loss))\n",
    "            #精确率\n",
    "            epoch_precision = running_precision / batch_num\n",
    "            print('{} Precision: {:.4f} '.format(phase, epoch_precision))\n",
    "            #召回率\n",
    "            epoch_recall = running_recall / batch_num\n",
    "            print('{} Recall: {:.4f} '.format(phase, epoch_recall))\n",
    "            f1score =(2*epoch_precision*epoch_recall)/(epoch_precision+epoch_recall)\n",
    "            print('{} f1score: {:.4f} '.format(phase, f1score))\n",
    "\n",
    "\n",
    "            if phase==\"train\":\n",
    "                file1.write(str(epoch_loss)+\"\\n\")\n",
    "                file3.write(str(epoch_precision)+\"\\n\")\n",
    "            if phase==\"val\":\n",
    "                file2.write(str(epoch_loss)+\"\\n\")\n",
    "                file4.write(str(epoch_precision)+\"\\n\")\n",
    "                file5.write(str(f1score) + \"\\n\")\n",
    "                file6.write(str(epoch_precision)+\"\\n\")\n",
    "                file7.write(str(epoch_recall)+\"\\n\")\n",
    "\n",
    "            torch.save(model.state_dict(),\"./model/\"+str(epoch) + \"_Resnet.pth\")\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算准确率——方式1\n",
    "# 设定一个阈值，当预测的概率值大于这个阈值，则认为这幅图像中含有这类标签\n",
    "def calculate_acuracy_mode_one(model_pred, labels):\n",
    "    # model_pred是经过sigmoid处理的，sigmoid处理后可以视为预测是这一类的概率\n",
    "    # 预测结果，大于这个阈值则视为预测正确\n",
    "    accuracy_th = 0.5\n",
    "    pred_result = model_pred > accuracy_th\n",
    "    pred_result = pred_result.float()\n",
    "    pred_one_num = torch.sum(pred_result)\n",
    "    if pred_one_num == 0:\n",
    "        return 0, 0\n",
    "    target_one_num = torch.sum(labels)\n",
    "    true_predict_num = torch.sum(pred_result * labels)\n",
    "    # 模型预测的结果中有多少个是正确的\n",
    "    precision = true_predict_num / pred_one_num\n",
    "    # 模型预测正确的结果中，占所有真实标签的数量\n",
    "    recall = true_predict_num / target_one_num\n",
    "\n",
    "    return precision.item(), recall.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "vgg1\n",
    "# 导入vgg网络模型\n",
    "model = models.vgg16(pretrained=True)\n",
    "# 获取最后一个全连接层的输入通道数\n",
    "\n",
    "\n",
    "# 重新创建一个新的 ResNet18 模型，并获取其全连接层的输入特征数量\n",
    "\n",
    "for param in model.parameters():  # params have requires_grad=True by default\n",
    "    param.requires_grad = False\n",
    "# num_ftrs = model.fc.in_features\n",
    "num_ftrs = model.classifier[6].in_features\n",
    "model.classifier[6] = nn.Linear(num_ftrs, 19)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "desnet2\n",
    "    model = models.densenet121(pretrained=True)\n",
    "    # 重新创建一个新的 ResNet18 模型，并获取其全连接层的输入特征数量\n",
    "    # 将其全连接层替换为一个新的具有4个输出节点的线性层\n",
    "    num_ftrs = model.classifier.in_features\n",
    "    model.classifier = nn.Linear(num_ftrs, 19)  # 分类种类个数\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # 导入resnet18网络模型\n",
    "    model = models.resnet18(pretrained=False)\n",
    "    # 将其全连接层替换为一个新的具有4个输出节点的线性层\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, 19)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "    if use_gpu:\n",
    "        model = model.cuda()\n",
    "    # 定义损失函数\n",
    "    criterion = nn.BCELoss()\n",
    "\n",
    "    # 为不同层设定不同的学习率\n",
    "    fc_params = list(map(id, model.parameters()))\n",
    "    base_params = filter(lambda p: id(p) not in fc_params, model.parameters())\n",
    "    params = [{\"params\": base_params, \"lr\":0.0001},\n",
    "              {\"params\": model.parameters(), \"lr\":0.001},]\n",
    "    optimizer_ft = torch.optim.SGD(params, momentum=0.9)\n",
    "    # 定义学习率的更新方式，每5个epoch修改一次学习率\n",
    "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=5, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/49\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\software\\anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1955 \n",
      "train Precision: 0.7554 \n",
      "train Recall: 0.5061 \n",
      "train f1score: 0.6061 \n",
      "val Loss: 0.1874 \n",
      "val Precision: 0.7595 \n",
      "val Recall: 0.5030 \n",
      "val f1score: 0.6052 \n",
      "Epoch 1/49\n",
      "----------\n",
      "train Loss: 0.1844 \n",
      "train Precision: 0.7601 \n",
      "train Recall: 0.5052 \n",
      "train f1score: 0.6070 \n",
      "val Loss: 0.1828 \n",
      "val Precision: 0.7595 \n",
      "val Recall: 0.5030 \n",
      "val f1score: 0.6052 \n",
      "Epoch 2/49\n",
      "----------\n",
      "train Loss: 0.1817 \n",
      "train Precision: 0.7600 \n",
      "train Recall: 0.5054 \n",
      "train f1score: 0.6071 \n",
      "val Loss: 0.1801 \n",
      "val Precision: 0.7595 \n",
      "val Recall: 0.5030 \n",
      "val f1score: 0.6052 \n",
      "Epoch 3/49\n",
      "----------\n",
      "train Loss: 0.1797 \n",
      "train Precision: 0.7600 \n",
      "train Recall: 0.5063 \n",
      "train f1score: 0.6077 \n",
      "val Loss: 0.1771 \n",
      "val Precision: 0.7597 \n",
      "val Recall: 0.5028 \n",
      "val f1score: 0.6051 \n",
      "Epoch 4/49\n",
      "----------\n",
      "train Loss: 0.1782 \n",
      "train Precision: 0.7601 \n",
      "train Recall: 0.5052 \n",
      "train f1score: 0.6070 \n",
      "val Loss: 0.1782 \n",
      "val Precision: 0.7571 \n",
      "val Recall: 0.5045 \n",
      "val f1score: 0.6055 \n",
      "Epoch 5/49\n",
      "----------\n",
      "train Loss: 0.1780 \n",
      "train Precision: 0.7600 \n",
      "train Recall: 0.5054 \n",
      "train f1score: 0.6071 \n",
      "val Loss: 0.1760 \n",
      "val Precision: 0.7586 \n",
      "val Recall: 0.5036 \n",
      "val f1score: 0.6053 \n",
      "Epoch 6/49\n",
      "----------\n",
      "train Loss: 0.1777 \n",
      "train Precision: 0.7600 \n",
      "train Recall: 0.5056 \n",
      "train f1score: 0.6073 \n",
      "val Loss: 0.1760 \n",
      "val Precision: 0.7590 \n",
      "val Recall: 0.5035 \n",
      "val f1score: 0.6054 \n",
      "Epoch 7/49\n",
      "----------\n",
      "train Loss: 0.1776 \n",
      "train Precision: 0.7600 \n",
      "train Recall: 0.5050 \n",
      "train f1score: 0.6068 \n",
      "val Loss: 0.1768 \n",
      "val Precision: 0.7589 \n",
      "val Recall: 0.5043 \n",
      "val f1score: 0.6059 \n",
      "Epoch 8/49\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    #训练  num_epoch=50\n",
    "    train_model(model, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型测试\n",
    "\n",
    "def test_model(model, imagepath):\n",
    "    Sigmoid_fun = nn.Sigmoid()\n",
    "    image = Load_Image_Information(imagepath)\n",
    "\n",
    "\n",
    "    image = data_transforms['val'](image)\n",
    "    image = torch.reshape(torch.tensor(image), (1, 3, 227, 227))\n",
    "    inputs = image.cuda()\n",
    "    outputs = model(inputs)\n",
    "    predlabel = Sigmoid_fun(outputs)\n",
    "    accuracy_th = 0.15\n",
    "    pred_result = predlabel > accuracy_th\n",
    "    outputlabel = []\n",
    "    for i in range(19):\n",
    "        if pred_result[0][i].item()==True:\n",
    "            outputlabel.append(i+1)\n",
    "    return  outputlabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model():\n",
    "\n",
    "    # 重新创建一个新的 ResNet18 模型，并获取其全连接层的输入特征数量\n",
    "    model = models.resnet18(pretrained=False)\n",
    "    # 将其全连接层替换为一个新的具有4个输出节点的线性层\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, 19)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\software\\anaconda\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "#单张图片的测试\n",
    "model = model()\n",
    "if use_gpu:\n",
    "    model = model.cuda()\n",
    "image_path = \"./18.jpg\"\n",
    "model.load_state_dict(torch.load(\"./3_Resnet.pth\"))\n",
    "model.eval()\n",
    "pred = test_model(model,imagepath=image_path)\n",
    "print(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
